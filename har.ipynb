{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "har.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOs2/A1LWeKHZaKJMFUiOUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivekSM1992/HumanActivityRecognition/blob/main/har.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp1T_Z0wEz9s",
        "outputId": "572ecb2e-46f2-46e8-f11d-269c880f3828"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JxZW0cEIEm_"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vuIOHJFHTBp",
        "outputId": "72f41c80-8917-457c-d925-3cdb2f52940f"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from glob import glob\n",
        "import random\n",
        "import sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy import dstack\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import math\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from numpy import mean\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "list_dir=os.listdir(\"/content/drive/MyDrive/A_DeviceMotion_data\")\n",
        "print(list_dir)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ups_12', 'std_14', 'wlk_15', 'sit_13', 'wlk_8', 'wlk_7', 'sit_5', 'ups_3', 'ups_4', 'std_6', 'dws_1', 'jog_9', 'dws_11', 'jog_16', 'dws_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX8-wFhHTAN0"
      },
      "source": [
        "Folders = glob('/content/drive/MyDrive/A_DeviceMotion_data/*_*')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAPoe0okTQGR"
      },
      "source": [
        "csv_files_train=[]\n",
        "csv_files_test=[]\n",
        "test_files_index=[]\n",
        "all_csv_files_train=[]\n",
        "all_csv_files_test=[]\n",
        "for item in Folders:\n",
        "    files_list=os.listdir(item)\n",
        "    total_file_size=len(files_list)\n",
        "    train_file_size=math.floor(total_file_size*0.75)\n",
        "    random.seed(0)\n",
        "    train_files_index=random.sample(range(total_file_size), train_file_size)\n",
        "    \n",
        "    for j in range(0,total_file_size):\n",
        "        if j not in train_files_index:\n",
        "            test_files_index.append(j)\n",
        "    #print(test_files_index)\n",
        "    #print(train_files_index)\n",
        "    \n",
        "    \n",
        "    for index in test_files_index:\n",
        "        file=files_list[index]\n",
        "        test_file=glob(item+'/'+str(file))\n",
        "        csv_files_test.append(test_file)\n",
        "    \n",
        "    for index in train_files_index:\n",
        "        file=files_list[index]\n",
        "        train_file=glob(item+'/'+str(file))\n",
        "        csv_files_train.append(train_file)\n",
        "     \n",
        "    test_files_index.clear()\n",
        "    train_files_index.clear()\n",
        "        \n",
        "for i in csv_files_train:\n",
        "        all_csv_files_train=all_csv_files_train+i\n",
        "\n",
        "\n",
        "for i in csv_files_test:\n",
        "        all_csv_files_test=all_csv_files_test+i"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci7Ir_00TZDR"
      },
      "source": [
        "def prepare_data(X,groundtruth):\n",
        "    WL=128\n",
        "    overlap=64\n",
        "    indexi=0\n",
        "    indexf=indexi+WL-1\n",
        "    container_X=[]\n",
        "    #container_Y=[]\n",
        "    num_timesteps,num_features = X.shape\n",
        "    #print(num_timesteps)\n",
        "    num_windows=(num_timesteps-WL)// (WL-overlap)\n",
        "    X_wind=np.zeros([num_windows,WL], dtype = float)\n",
        "    Y_wind=np.full([num_windows, 1],groundtruth,dtype = int)\n",
        "    #print(num_features)\n",
        "    \n",
        "    \n",
        "    for features in range(0,num_features):\n",
        "        indexi=0\n",
        "        indexf=indexi+WL-1\n",
        "        #print(X)\n",
        "        for windows in range(0,num_windows):\n",
        "            X_wind[windows,:]=X.iloc[indexi:(indexf+1),features]\n",
        "            \n",
        "            indexi=indexf-overlap+1\n",
        "            #print(indexi)\n",
        "            indexf=indexi+WL-1\n",
        "        container_X.append(X_wind)\n",
        "        #container_Y.append(Y_wind)\n",
        "    container_X=dstack(container_X)\n",
        "    #container_Y=dstack(container_Y)\n",
        "    return container_X,Y_wind,num_windows"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g37jyHhtTbnh"
      },
      "source": [
        "def process_data(csv_files):\n",
        "    X_list=[]\n",
        "    Y_list=[]\n",
        "    Total_num_windows=0\n",
        "    daddy_frame = pd.DataFrame()\n",
        "    #print(X_list)\n",
        "    for csvs in csv_files:\n",
        "        for items in gt_list:\n",
        "            if (str(csvs).find(items) != -1):\n",
        "                break\n",
        "        for subjects in sub_list:\n",
        "            if (str(csvs).find(subjects) != -1):\n",
        "                break\n",
        "        temp_df=pd.read_csv(csvs)\n",
        "        #print(temp_df)\n",
        "        #temp_df=temp_df.loc[0:1028, :]\n",
        "        temp_df=temp_df.drop(labels='Unnamed: 0', axis=1)\n",
        "        temp_df['ang_res']=temp_df['rotationRate.x'] ** 2+ temp_df['rotationRate.y'] ** 2+ temp_df['rotationRate.z'] ** 2\n",
        "        temp_df['ang_res']=temp_df['ang_res'].apply(np.sqrt)\n",
        "        temp_df['linear_res']=temp_df['userAcceleration.x'] ** 2+ temp_df['userAcceleration.y'] ** 2+ temp_df['userAcceleration.z'] ** 2\n",
        "        temp_df['linear_res']=temp_df['linear_res'].apply(np.sqrt)\n",
        "    \n",
        "        temp_df_scale=temp_df.loc[:,['rotationRate.x','rotationRate.y','rotationRate.z','linear_res']]\n",
        "        scaler = MinMaxScaler((-1,1))\n",
        "        scaler.fit(temp_df_scale)\n",
        "        scaled_X=scaler.transform(temp_df_scale)\n",
        "        \n",
        "        for key, value in gt_list_dict.items():\n",
        "            if key == items:\n",
        "                items=value\n",
        "        #print(temp_df_scale)\n",
        "        process_data_X,process_data_Y,num_windows=prepare_data(temp_df_scale,items)\n",
        "        X_list.append(process_data_X)\n",
        "        Y_list.append(process_data_Y)\n",
        "        Total_num_windows=Total_num_windows+num_windows\n",
        "        temp_df['groundtruth']=items\n",
        "        temp_df['subjects']=subjects\n",
        "        #print(temp_df.head())\n",
        "        #print((temp_df.count))\n",
        "        daddy_frame=daddy_frame.append(temp_df)\n",
        "    X_list=np.array(X_list)\n",
        "    Y_list=np.array(Y_list)\n",
        "    return daddy_frame,X_list,Y_list,Total_num_windows"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub8qvqw9TiaG"
      },
      "source": [
        "sub_list=[]\n",
        "for i in range(1,25):\n",
        "    string='sub_'+str(i)+'.csv'\n",
        "    sub_list.append(string)\n",
        "gt_list=['dws','jog','sit','ups','wlk','std']\n",
        "gt_list_dict={'dws':0,'jog':1,'sit':2,'ups':3,'wlk':4,'std':5}\n",
        "\n",
        "def load_dataset():\n",
        "    \n",
        "    master_frame_train = pd.DataFrame()\n",
        "    master_frame_test = pd.DataFrame()\n",
        "    \n",
        "\n",
        "    master_frame_train,Train_X,Train_Y,Total_num_windows_train=process_data(all_csv_files_train)\n",
        "    \n",
        "    master_frame_test,Test_X,Test_Y,Total_num_windows_test=process_data(all_csv_files_test)\n",
        "    #print(master_frame_test)\n",
        "\n",
        "\n",
        "   # print(Train_Y[1].shape)\n",
        "    WL=128\n",
        "    num_features=4\n",
        "    num_windows_train=0\n",
        "    num_windows_test=0\n",
        "    Train_X_array=np.zeros([Total_num_windows_train,WL,num_features], dtype = float)\n",
        "    Train_Y_array=np.zeros([Total_num_windows_train,1], dtype = int)\n",
        "    Test_X_array=np.zeros([Total_num_windows_test,WL,num_features], dtype = float)\n",
        "    Test_Y_array=np.zeros([Total_num_windows_test,1], dtype = int)\n",
        "    for i in range(0,Train_X.size):\n",
        "        \n",
        "        for j in range(0,Train_X[i].shape[0]):\n",
        "            \n",
        "            Train_X_array[num_windows_train+j]=Train_X[i][j]\n",
        "            Train_Y_array[num_windows_train+j]=Train_Y[i][j]\n",
        "        num_windows_train=num_windows_train+(j+1)\n",
        "    \n",
        "    for i in range(0,Test_X.size):\n",
        "        #print(i)\n",
        "        for j in range(0,Test_X[i].shape[0]):\n",
        "            #print(j)\n",
        "            Test_X_array[num_windows_test+j]=Test_X[i][j]\n",
        "            Test_Y_array[num_windows_test+j]=Test_Y[i][j]\n",
        "        num_windows_test=num_windows_test+(j+1)\n",
        "    print(Train_Y_array.shape,Test_Y_array.shape)    \n",
        "    # one hot encode y\n",
        "    Train_Y_gt=Train_Y_array\n",
        "    Train_Y_array = to_categorical(Train_Y_array)\n",
        "    Test_Y_gt=Test_Y_array\n",
        "    Test_Y_array = to_categorical(Test_Y_array)\n",
        "    print(Train_X_array.shape, Train_Y_array.shape, Test_X_array.shape, Test_Y_array.shape)\n",
        "    return Train_X_array, Train_Y_array, Test_X_array, Test_Y_array,Test_Y_gt,Train_Y_gt"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIY3vOISlJ4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f7e2e5c-f5da-4e73-b800-c5d7273d8be8"
      },
      "source": [
        " from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy,test_Y_gt,train_Y_gt,type_model):\n",
        "    verbose, epochs, batch_size = 1, 50, 64\n",
        "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "    model = Sequential()\n",
        "    type_model=\"CNN\"\n",
        "    if(type_model==\"CNN\"):\n",
        "        model.add(Conv1D(filters=64, kernel_size=16, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "        model.add(Conv1D(filters=32, kernel_size=16, activation='relu'))\n",
        "  #model.add(Dropout(0.5))\n",
        "  #model.add(Dropout(0.5))\n",
        "        model.add(MaxPooling1D(pool_size=4))\n",
        "  #model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "  #model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "  #model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(100, activation='relu'))\n",
        "        model.add(Dense(n_outputs, activation='softmax'))\n",
        "    else:\n",
        "        model.add(LSTM(64, input_shape=(n_timesteps,n_features)))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(n_outputs, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # fit network\n",
        "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "    # evaluate model\n",
        "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=2)\n",
        " \n",
        "    yhat_probs = model.predict(testX, verbose=0)\n",
        "    #print(yhat_probs)\n",
        "  # predict crisp classes for test set\n",
        "    yhat_classes = np.argmax(model.predict(testX), axis=-1)\n",
        "    print(yhat_classes)\n",
        "    target_names = ['Walking Downstairs','Jogging','Sitting', 'Walking Upstairs','Walking','Standing']\n",
        "    print(classification_report(test_Y_gt, yhat_classes, target_names=target_names))\n",
        "    confusion = confusion_matrix(test_Y_gt, yhat_classes)\n",
        "    print('Confusion Matrix\\n')\n",
        "    print(confusion)\n",
        "    return accuracy\n",
        " \n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        " \n",
        "# run an experiment\n",
        "def run_experiment(repeats=2):\n",
        "\t# load data\n",
        "\ttrainX, trainy, testX, testy,test_Y_gt,train_Y_gt = load_dataset()\n",
        "\tprint(trainX)\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tfor r in range(repeats):\n",
        "\t\tscore = evaluate_model(trainX, trainy, testX, testy,test_Y_gt,train_Y_gt,\"LSTM\")\n",
        "\t\tscore = score * 100.0\n",
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
        "\t\tscores.append(score)\n",
        "\t# summarize results\n",
        "\tsummarize_results(scores)\n",
        "\n",
        " \n",
        "# run the experiment\n",
        "run_experiment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15783, 1) (5396, 1)\n",
            "(15783, 128, 4) (15783, 6) (5396, 128, 4) (5396, 6)\n",
            "[[[2.64753792 2.64753792 2.64753792 2.64753792]\n",
            "  [0.87340286 0.87340286 0.87340286 0.87340286]\n",
            "  [1.17312502 1.17312502 1.17312502 1.17312502]\n",
            "  ...\n",
            "  [0.6367619  0.6367619  0.6367619  0.6367619 ]\n",
            "  [0.53612124 0.53612124 0.53612124 0.53612124]\n",
            "  [0.43328612 0.43328612 0.43328612 0.43328612]]\n",
            "\n",
            " [[0.89999376 0.89999376 0.89999376 0.89999376]\n",
            "  [0.80182436 0.80182436 0.80182436 0.80182436]\n",
            "  [0.9123571  0.9123571  0.9123571  0.9123571 ]\n",
            "  ...\n",
            "  [1.01925185 1.01925185 1.01925185 1.01925185]\n",
            "  [0.89933323 0.89933323 0.89933323 0.89933323]\n",
            "  [0.72555377 0.72555377 0.72555377 0.72555377]]\n",
            "\n",
            " [[0.56623496 0.56623496 0.56623496 0.56623496]\n",
            "  [0.54740049 0.54740049 0.54740049 0.54740049]\n",
            "  [0.6496284  0.6496284  0.6496284  0.6496284 ]\n",
            "  ...\n",
            "  [2.55298546 2.55298546 2.55298546 2.55298546]\n",
            "  [0.43676464 0.43676464 0.43676464 0.43676464]\n",
            "  [0.16718532 0.16718532 0.16718532 0.16718532]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.59164619 0.59164619 0.59164619 0.59164619]\n",
            "  [0.3166742  0.3166742  0.3166742  0.3166742 ]\n",
            "  [0.18600672 0.18600672 0.18600672 0.18600672]\n",
            "  ...\n",
            "  [0.90074412 0.90074412 0.90074412 0.90074412]\n",
            "  [0.19298758 0.19298758 0.19298758 0.19298758]\n",
            "  [0.25549617 0.25549617 0.25549617 0.25549617]]\n",
            "\n",
            " [[0.10638332 0.10638332 0.10638332 0.10638332]\n",
            "  [0.36151508 0.36151508 0.36151508 0.36151508]\n",
            "  [0.25655265 0.25655265 0.25655265 0.25655265]\n",
            "  ...\n",
            "  [0.45313193 0.45313193 0.45313193 0.45313193]\n",
            "  [0.34390557 0.34390557 0.34390557 0.34390557]\n",
            "  [0.35555775 0.35555775 0.35555775 0.35555775]]\n",
            "\n",
            " [[0.39052618 0.39052618 0.39052618 0.39052618]\n",
            "  [0.43049556 0.43049556 0.43049556 0.43049556]\n",
            "  [0.45091208 0.45091208 0.45091208 0.45091208]\n",
            "  ...\n",
            "  [0.11443233 0.11443233 0.11443233 0.11443233]\n",
            "  [0.18942986 0.18942986 0.18942986 0.18942986]\n",
            "  [0.27534891 0.27534891 0.27534891 0.27534891]]]\n",
            "Epoch 1/50\n",
            "247/247 [==============================] - 18s 69ms/step - loss: 0.8211 - accuracy: 0.6227\n",
            "Epoch 2/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.5369 - accuracy: 0.7682\n",
            "Epoch 3/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.4674 - accuracy: 0.8047\n",
            "Epoch 4/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.4364 - accuracy: 0.8174\n",
            "Epoch 5/50\n",
            "247/247 [==============================] - 17s 70ms/step - loss: 0.4076 - accuracy: 0.8308\n",
            "Epoch 6/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.3847 - accuracy: 0.8389\n",
            "Epoch 7/50\n",
            "247/247 [==============================] - 17s 70ms/step - loss: 0.3694 - accuracy: 0.8431\n",
            "Epoch 8/50\n",
            "247/247 [==============================] - 17s 70ms/step - loss: 0.3491 - accuracy: 0.8503\n",
            "Epoch 9/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.3303 - accuracy: 0.8579\n",
            "Epoch 10/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.3241 - accuracy: 0.8611\n",
            "Epoch 11/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.3030 - accuracy: 0.8677\n",
            "Epoch 12/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.3000 - accuracy: 0.8720\n",
            "Epoch 13/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.2861 - accuracy: 0.8752\n",
            "Epoch 14/50\n",
            "247/247 [==============================] - 17s 70ms/step - loss: 0.2756 - accuracy: 0.8804\n",
            "Epoch 15/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.2591 - accuracy: 0.8854\n",
            "Epoch 16/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.2500 - accuracy: 0.8917\n",
            "Epoch 17/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.2423 - accuracy: 0.8956\n",
            "Epoch 18/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.2482 - accuracy: 0.8954\n",
            "Epoch 19/50\n",
            "247/247 [==============================] - 17s 70ms/step - loss: 0.2214 - accuracy: 0.9027\n",
            "Epoch 20/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2192 - accuracy: 0.9052\n",
            "Epoch 21/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.2170 - accuracy: 0.9093\n",
            "Epoch 22/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.2159 - accuracy: 0.9072\n",
            "Epoch 23/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2078 - accuracy: 0.9099\n",
            "Epoch 24/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2014 - accuracy: 0.9105\n",
            "Epoch 25/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2138 - accuracy: 0.9093\n",
            "Epoch 26/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1978 - accuracy: 0.9156\n",
            "Epoch 27/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.1907 - accuracy: 0.9184\n",
            "Epoch 28/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1859 - accuracy: 0.9186\n",
            "Epoch 29/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1853 - accuracy: 0.9188\n",
            "Epoch 30/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.1849 - accuracy: 0.9218\n",
            "Epoch 31/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.1866 - accuracy: 0.9224\n",
            "Epoch 32/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.1792 - accuracy: 0.9235\n",
            "Epoch 33/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.1772 - accuracy: 0.9250\n",
            "Epoch 34/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.1669 - accuracy: 0.9276\n",
            "Epoch 35/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1635 - accuracy: 0.9290\n",
            "Epoch 36/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1874 - accuracy: 0.9226\n",
            "Epoch 37/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.1750 - accuracy: 0.9288\n",
            "Epoch 38/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1596 - accuracy: 0.9320\n",
            "Epoch 39/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.1538 - accuracy: 0.9342\n",
            "Epoch 40/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1561 - accuracy: 0.9325\n",
            "Epoch 41/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.1715 - accuracy: 0.9292\n",
            "Epoch 42/50\n",
            "247/247 [==============================] - 17s 70ms/step - loss: 0.1596 - accuracy: 0.9347\n",
            "Epoch 43/50\n",
            "247/247 [==============================] - 17s 71ms/step - loss: 0.1496 - accuracy: 0.9377\n",
            "Epoch 44/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1453 - accuracy: 0.9383\n",
            "Epoch 45/50\n",
            "247/247 [==============================] - 17s 70ms/step - loss: 0.1424 - accuracy: 0.9411\n",
            "Epoch 46/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1368 - accuracy: 0.9409\n",
            "Epoch 47/50\n",
            "247/247 [==============================] - 17s 70ms/step - loss: 0.1502 - accuracy: 0.9381\n",
            "Epoch 48/50\n",
            "247/247 [==============================] - 17s 70ms/step - loss: 0.1704 - accuracy: 0.9325\n",
            "Epoch 49/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1464 - accuracy: 0.9383\n",
            "Epoch 50/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.1310 - accuracy: 0.9445\n",
            "85/85 - 1s - loss: 1.1747 - accuracy: 0.7722 - 1s/epoch - 15ms/step\n",
            "[0 3 3 ... 3 3 3]\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "Walking Downstairs       0.63      0.77      0.69       458\n",
            "           Jogging       0.95      0.97      0.96       526\n",
            "           Sitting       0.85      0.61      0.71      1397\n",
            "  Walking Upstairs       0.66      0.85      0.74       610\n",
            "           Walking       0.97      0.74      0.84      1279\n",
            "          Standing       0.64      0.87      0.74      1126\n",
            "\n",
            "          accuracy                           0.77      5396\n",
            "         macro avg       0.78      0.80      0.78      5396\n",
            "      weighted avg       0.80      0.77      0.77      5396\n",
            "\n",
            "Confusion Matrix\n",
            "\n",
            "[[351  27   0  62  17   1]\n",
            " [ 10 510   0   5   1   0]\n",
            " [  1   0 859   1   0 536]\n",
            " [ 74   0   1 519  16   0]\n",
            " [123   1   1 201 950   3]\n",
            " [  0   1 145   2   0 978]]\n",
            ">#1: 77.224\n",
            "Epoch 1/50\n",
            "247/247 [==============================] - 18s 69ms/step - loss: 0.8589 - accuracy: 0.6222\n",
            "Epoch 2/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.5415 - accuracy: 0.7691\n",
            "Epoch 3/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.4946 - accuracy: 0.7868\n",
            "Epoch 4/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.4537 - accuracy: 0.8066\n",
            "Epoch 5/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.4315 - accuracy: 0.8161\n",
            "Epoch 6/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.4059 - accuracy: 0.8260\n",
            "Epoch 7/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.3919 - accuracy: 0.8338\n",
            "Epoch 8/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.3731 - accuracy: 0.8431\n",
            "Epoch 9/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.3609 - accuracy: 0.8494\n",
            "Epoch 10/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.3431 - accuracy: 0.8526\n",
            "Epoch 11/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.3292 - accuracy: 0.8593\n",
            "Epoch 12/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.3191 - accuracy: 0.8640\n",
            "Epoch 13/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.2961 - accuracy: 0.8728\n",
            "Epoch 14/50\n",
            "247/247 [==============================] - 17s 70ms/step - loss: 0.2894 - accuracy: 0.8742\n",
            "Epoch 15/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2822 - accuracy: 0.8747\n",
            "Epoch 16/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2721 - accuracy: 0.8819\n",
            "Epoch 17/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2625 - accuracy: 0.8861\n",
            "Epoch 18/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2543 - accuracy: 0.8895\n",
            "Epoch 19/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2533 - accuracy: 0.8913\n",
            "Epoch 20/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2425 - accuracy: 0.8956\n",
            "Epoch 21/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2235 - accuracy: 0.9005\n",
            "Epoch 22/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2142 - accuracy: 0.9060\n",
            "Epoch 23/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2110 - accuracy: 0.9090\n",
            "Epoch 24/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2039 - accuracy: 0.9113\n",
            "Epoch 25/50\n",
            "247/247 [==============================] - 17s 69ms/step - loss: 0.2010 - accuracy: 0.9150\n",
            "Epoch 26/50\n",
            "247/247 [==============================] - 17s 68ms/step - loss: 0.2053 - accuracy: 0.9112\n",
            "Epoch 27/50\n",
            " 58/247 [======>.......................] - ETA: 12s - loss: 0.1823 - accuracy: 0.9197"
          ]
        }
      ]
    }
  ]
}